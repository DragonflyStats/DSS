\documentclass[]{article}
\usepackage{framed}
\usepackage{graphicx}
\begin{document}



\section{Getting and Cleaning Data: Week 1 Quiz}
%-----------------------------------------------------------------%
\begin{verbatim}
install.packages("data.table", "xlsx", "XML")
\end{verbatim}
\newpage
\subsection*{Question 1}

The American Community Survey distributes downloadable data about United States communities. 
Download the 2006 microdata survey about housing for the state of Idaho using \texttt{download.file()} from here: 

\begin{verbatim}
https://dl.dropbox.com/u/7710864/data/csv_hid/ss06hid.csv

or here:

https://spark-public.s3.amazonaws.com/dataanalysis/ss06hid.csv 
\end{verbatim}
and load the data into \texttt{R}. You will use this data for the next several questions. 

\noindent \textbf{\textit{Code Book}}\\
The code book, describing the variable names is here: 

\begin{verbatim}
https://dl.dropbox.com/u/7710864/data/PUMSDataDict06.pdf

or here: 

https://spark-public.s3.amazonaws.com/dataanalysis/PUMSDataDict06.pdf
\end{verbatim}
\bigskip
How many housing units in this survey were worth more than \$1,000,000?
% **53**

\begin{framed}
\begin{verbatim}
# Download 2006 microdata survey 
# re: housing for Idaho using download.file()
# setwd("~/DA")
download.file(
 'https://spark-public.s3.amazonaws.com/dataanalysis/ss06hid.csv',
              "ss06hid.csv", method="curl")

# Download the code book:
# download.file(
 'https://spark-public.s3.amazonaws.com/dataanalysis/PUMSDataDict06.pdf',
              "PUMSDataDict06.pdf", method="curl")

# load the data into R
idahoData <- read.csv("ss06hid.csv", header=TRUE)

# are we sure it's just Idaho data?
table(idahoData$ST)
#Check the PDF - what does 16 mean?

#any missing data?
summary(idahoData$ST)

# How many housing units [are] worth more than $1,000,000?
table(idahoData$TYPE,idahoData$VAL)
\end{verbatim}
\end{framed}

\begin{framed}
\begin{verbatim}
#from local files
idahoData <- read.csv("daquiz2.csv", header=TRUE)

\end{verbatim}
\end{framed}

%-----------------------------------------------------------------%
\newpage
\subsection*{ Question 2}

\begin{itemize}
\item Consider the variable FES. 
\item Which of the "tidy data" principles does this variable violate?
\end{itemize}

%READY
\textbf{\textit{Revision}}\\
What are the three characteristics of tidy data?

\begin{itemize}
\item ``\textit{\textbf{Tidy data}}" by Hadley Wickham (RStudio)
\item Submission to Journal of Statistical Software
\item (http://vita.had.co.nz/papers/tidy-data.pdf)
\end{itemize}
Three Principles from Hadley Wickham's paper
\begin{itemize}
\item[1.] Each variable forms a column, 
\item[2.] Each observation forms a row, 
\item[3.] Each table/file stores data about one kind of observation.
\end{itemize}

\begin{framed} 
\begin{verbatim}
# let's check it out
unique(idahoData$FES)
\end{verbatim}
\end{framed} 
\textbf{Options}
\begin{itemize}
\item[(i)]  Each tidy data table contains information about only one type of observation.\\
(Not so)

\item[(ii)]  Each variable in a tidy data set has been transformed to be interpretable.
(No)

\item[(iii)]  Tidy data has no missing values.

\item[(iv)]  Tidy data has one variable per column.
\end{itemize}
  



%-----------------------------------------------------------------%
\newpage
\subsection*{Question 3}

Download the Excel spreadsheet on Natural Gas Aquisition Program here: 

\begin{verbatim}
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx 
\end{verbatim}

Read rows 18-23 and columns 7-15 into R and assign the result to a variable called:  \texttt{dat}  
\bigskip

What is the value of:  
\begin{framed}
\begin{verbatim}
sum(dat$Zip*dat$Ext,na.rm=T)  
\end{verbatim}
\end{framed}


\noindent \textit{(original data source: http://catalog.data.gov/dataset/natural-gas-acquisition-program)}

\begin{itemize} 
\item[(i)] NA 

\item[(ii)] 36534720 

\item[(iii)]  154339 

\item[(iv)] 33544718 
\end{itemize} 
\newpage
\begin{framed}
\begin{verbatim}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FDATA.gov_NGAP.xlsx"
getwd()
download.file(url=fileUrl, destfile="gov_NGAP.xlsx", mode="w", method="curl")

colIndex <- 7:15
rowIndex <- 18:23

library(xlsx)

dat <- read.xlsx(file="gov_NGAP.xlsx",sheetIndex=1,colIndex=colIndx,startRow=18, endRow=23, header=TRUE)
head(dat)
summary(dat)

sum(dat$Zip*dat$Ext,na.rm=T) 

\end{verbatim}
\end{framed}



%-----------------------------------------------------------------%
\newpage
\subsection*{Question 4}

Read the XML data on Baltimore restaurants from here: 

\begin{verbatim}
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml 
\end{verbatim}
How many restaurants have zipcode 21231? 

Remark : Use \texttt{http}  instead of \texttt{https} , which caused the message Error: \texttt{XML content does not 
seem to be XML: }
\begin{itemize}
\item[(i)] 100 

\item[(ii)] 127 

\item[(iii)] 130 

\item[(iv)] 28
\end{itemize}

\begin{verbatim}
http://www.omegahat.org/RSXML/shortIntro.pdf
\end{verbatim}

\newpage

\begin{framed}
\begin{verbatim}

fileUrl <- "http://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Frestaurants.xml"
doc <- xmlTreeParse(fileUrl, useInternal=TRUE)
doc
rootNode <- xmlRoot(doc)
rootNode

rootNode[[1]]

rootNode[[1]][[1]]

names(rootNode[[1]][[1]])

class(rootNode)
mode(rootNode)

xmlName(rootNode)
names(rootNode)


zipcode <- xpathSApply(rootNode, "//zipcode", xmlValue)
table(zipcode == 21231)

## Also
length(zipcode[zipcode==21231])

## Also
sum(xpathSApply(rootNode, "//zipcode", xmlValue)==21231) 



\end{verbatim}
\end{framed}

%-----------------------------------------------------------------%
\newpage
\subsection*{Question 5}
 
The American Community Survey distributes downloadable data about United States communities. \\
\\
Download the 2006 microdata survey about housing for the state of Idaho using \texttt{download.file()} from here:
 
\begin{verbatim}
https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv
\end{verbatim}
 using the \texttt{fread()} command load the data into an R object \texttt{DT}.\\ Which of the following is the fastest way to calculate the average value of the variable pwgtp15  broken down by sex using the data.table package? 

\begin{itemize}
\item[(i)] sapply(split(DT$pwgtp15,DT$SEX),mean) 

\item[(ii)] rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2] 

\item[(iii)] mean(DT$pwgtp15,by=DT$SEX) 

\item[(iv)] mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15) 

\item[(v)] DT[,mean(pwgtp15),by=SEX] 

\item[(vi)] tapply(DT$pwgtp15,DT$SEX,mean)
\end{itemize}

\begin{framed}
\begin{verbatim}
help(proc.time)
help(system.time)
\end{verbatim}
\end{framed}
Load in the data
\begin{framed}
\begin{verbatim}
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv"
download.file(fileUrl, destfile="./data/microdata3.csv", method="curl")
DT <- fread("./data/microdata3.csv")
file.info("./data/microdata3.csv")$size
\end{verbatim}
\end{framed}
\newpage
\begin{framed}
\begin{verbatim}
# Option A
st = proc.time()
for (i in 1:100){
  sapply(split(DT$pwgtp15,DT$SEX),mean)
}
print (proc.time() - st)

# Option B
st = proc.time()
for (i in 1:100){
  rowMeans(DT)[DT$SEX==1];rowMeans(DT)[DT$SEX==2]
}
print (proc.time() - st)

# Option C
st = proc.time()
for (i in 1:100){
  mean(DT$pwgtp15,by=DT$SEX)
}
print (proc.time() - st)

# Option D
st = proc.time()
for (i in 1:100){
  tapply(DT$pwgtp15,DT$SEX,mean)
}
print (proc.time() - st)

# Option E
st = proc.time()
for (i in 1:100){
  mean(DT[DT$SEX==1,]$pwgtp15);mean(DT[DT$SEX==2,]$pwgtp15)
}
print (proc.time() - st)

# Option F
st = proc.time()
for (i in 1:100){
  DT[,mean(pwgtp15),by=SEX]
}
print (proc.time() - st)
\end{verbatim}
\end{framed}

\newpage
\begin{framed}
\begin{verbatim}
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(mean(DT[DT$SEX==1,]$pwgtp15))+system.time(mean(DT[DT$SEX==2,]$pwgtp15))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(rowMeans(DT)[DT$SEX==1])+system.time(rowMeans(DT)[DT$SEX==2]
\end{verbatim}
\end{framed}


%-----------------------------------------------------------------%
\newpage
\subsection*{Optional Question elated to Question 1 and 2}

\begin{itemize}
\item Use the data from previous question. 
\item How many households have 3 bedrooms and and 4 total rooms? 
\item How many households have 2 bedrooms and 5 total rooms? 
\item How many households have 2 bedrooms and 7 total rooms?
\end{itemize}
\begin{framed}
\begin{verbatim}
#USING TABLE
#Rooms on Rows , Bedrooms on Columns
#dnn adds dimension names

table(idahoData$RMS,idahoData$BDS,dnn=list("RMS","BDS"))

\end{verbatim}
\end{framed}
Another Way of Doing it
\begin{framed}
\begin{verbatim}
# How many households have 3 bedrooms and 4 total rooms?
nrow(idahoData[!is.na(idahoData$BDS) & idahoData$BDS==3 &
                 !is.na(idahoData$BDS) & idahoData$RMS==4,])
# How many households have 2 bedrooms and 5 total rooms?
nrow(idahoData[!is.na(idahoData$BDS) & idahoData$BDS==2 &
                 !is.na(idahoData$BDS) & idahoData$RMS==5,])
# How many households have 2 bedrooms and 7 total rooms?
nrow(idahoData[!is.na(idahoData$BDS) & idahoData$BDS==2 &
                 !is.na(idahoData$BDS) & idahoData$RMS==7,])

\end{verbatim}
\end{framed}
% **148, 386, 49**


%-----------------------------------------------------------------%
\newpage
\subsection*{Optional Question elated to Question 1 and 2}
\begin{itemize}
\item Use the data from previous Questions 
\item Create a logical vector that identifies the households on greater than 10 acres who sold more than \$10,000 worth of agriculture products. 
\item Assign that logical vector to the variable `\texttt{agricultureLogical}`. 
\item Apply the `\texttt{which()} function like this to identify the rows of the data frame where the logical vector is `TRUE`.
\end{itemize}

\begin{framed} 
\begin{verbatim}
# Like this (this wont run yet)
 which(agricultureLogical) 
\end{verbatim}
\end{framed} 

What are the first 3 values that result?

\begin{framed} \begin{verbatim}
# Showing off a bit
q6cols <- c("ACR", "AGS")
which(names(idahoData) %in% q6cols)  

# logical vector
agricultureLogical <- idahoData$ACR==3 & idahoData$AGS==6

# and:
 which(agricultureLogical) 
\end{verbatim}\end{framed} 

%**125, 238, 262**

%-----------------------------------------------------------------%
\newpage
\subsection*{Optional Question elated to Question 1 and 2}

\begin{itemize}
\item Use the data from previous question. 
\item Create a logical vector that identifies the households on greater than 10 acres who
 sold more than \$10,000 worth of agriculture products. 
\item Assign that logical vector to the variable \texttt{agricultureLogical}. 
\item Apply the \texttt{which()} function like this to identify the rows of the 
data frame where the logical vector is TRUE and assign it to the variable indexes. 
\end{itemize}

\begin{framed} \begin{verbatim}
indexes =  which(agricultureLogical) 
\end{verbatim}\end{framed} 

If your data frame for the complete data is called \texttt{dataFrame} you can create a data frame 
with only the above subset with the command: 

\begin{framed} 
\begin{verbatim}
subsetDataFrame  = dataFrame[indexes,] 
\end{verbatim}
\end{framed} 

\noindent Note that we are subsetting this way because the NA values in the variables 
will cause problems if you subset directly with the logical statement. 


\noindent How many households in the subsetDataFrame have a missing value for the mortgage status 
(MRGX) variable?

\begin{framed} 
\begin{verbatim}
indexes <- which(agricultureLogical)
subsetIdahoData <- idahoData[indexes,]

# And then:
nrow(subsetIdahoData[is.na(subsetIdahoData$MRGX),])
\end{verbatim}
\end{framed} 

%**8**
%-----------------------------------------------------------------%
\newpage
\subsection*{Optional Question Related to Question 5}

In addition to the data from Question 3, the American Community Survey also collects data about populations. 
Using `download.file()`, download the population record data from: 

\begin{verbatim}
https://dl.dropbox.com/u/7710864/data/csv_hid/ss06pid.csv 
\end{verbatim}
or here:
\begin{verbatim}
https://spark-public.s3.amazonaws.com/dataanalysis/ss06pid.csv
\end{verbatim}

\begin{itemize}
\item Load the data into \texttt{R}. Assign the housing data from Question 3 to a data frame `\texttt{housingData}` and the population data from above to a data frame `populationData`.

\item Use the merge command to merge these data sets based only on the common identifier "SERIALNO". 

\item What is the dimension of the resulting data set? 
\end{itemize}
%[OPTIONAL] For fun, you might look at the data and see what happened when they merged.

\begin{framed} 
\begin{verbatim}
download.file(
'https://spark-public.s3.amazonaws.com/dataanalysis/ss06pid.csv',
              'ss06pid.csv', method='curl')

rm(idahoData)
housingData <- read.csv("ss06hid.csv", header=TRUE)
populationData <- read.csv("ss06pid.csv", header=TRUE)

dim(merge(housingData, 
 populationData, by="SERIALNO", all=TRUE))
\end{verbatim}
\end{framed} 

% **number of rows = 15451, number of columns = 426**

\end{document}

%-----------------------------------------------------------------%
\newpage
\subsection*{Question 8}
\begin{itemize}
\item Use the data from Question 3.
\item Apply `\texttt{strsplit()}` to split all the names of the data frame on the characters "wgtp". 
\item What is the value of the 123 element of the resulting list?
\end{itemize}

\begin{framed} \begin{verbatim}
List <- strsplit(names(idahoData), "wgtp")
List[123]
\end{verbatim}\end{framed} 

%**"" "15"**

%-----------------------------------------------------------------%
\newpage
\subsection*{Question 9}

What are the 0\% and 100\% quantiles of the variable \texttt{YBL}? Is there anything wrong with these values?
\textit{ Hint: you may need to use the \texttt{na.rm} parameter.}

\begin{framed} 
\begin{verbatim}
quantile(idahoData$YBL, na.rm=TRUE)
#  0%  25%  50%  75% 100% 
#  -1    3    5    7   25 
\end{verbatim}
\end{framed} 


\end{document}
